%% Needed for the postscript graphics.
%%\input epsf

%% My macros.
\input macro

%% The length of a page is 10in.
%%\vsize=10in

%\font\helv = phvr
%\font\times = ptmr
%\font\zap = pzcmi at 12pt
%\font\pal = pplro at 12pt

%% Don't indent paragraphs.
\parindent=0pt
\parskip=.5\baselineskip
\baselineskip = 1.1\baselineskip

\footline{\hss\tenrm\folio\hss}

\mansubtitle{Measure Theoretic Conditional Expectation}
        {in an Elementary Setting}
{R. Scott McIntire}{Sep 27, 2024}

\section{Overview}
The measure theoretic approach to conditional expectation can be confusing
when compared to the traditional approach.
In what follows we go through a conditional 
expectation problem within a discrete and familiar setting in an attempt 
to reduce this confusion. In the example shown, we show explicitly that the 
conditional expectation function is non-measurable in the origin 
measure space.


\section{Elementary Probability Example}
Let $X = \{D_1, D_2, D_3, D_4, D_5, D_6\}$ and define a function $P$ by 
$P(D_i) = \frac{1}{6}$, for $i\in \{1,2,3,4,5,6\}$. The intent is that $P$ will 
become a probability measure for the space we construct.
Let ${\cal E} = 2^X$ be the $\sigma$-algebra 
consisting of the power set of $X$. We extend $P$ for every element in the $\sigma$-algebra.
Since the $\sigma$-algebra consists of all sets 
we need an assignment for an arbitrary set, $A$. 
The assignment is $P(A) = \frac{|A|}{6}$; that is, the cardinality of the set divided by 6.
We now have a measure space; in fact, a probability space: $(P,X,{\cal E})$.
Note that for a probability space we need an event space, $X$, a $\sigma$-algebra of sets 
(in the discrete case just an algebra), and a function $P$ which takes 
elements of the $\sigma$-algebra to [0,1] with the following properties:

\beginEnum
\item{$P(X) = 1$}
\item{$P(\emptyset) = 0$.}
\item{$
P\bigl(\mathop{\bigcup}_{i=1}^N A_i\bigr) = \sum_{i=1}^N P(A_i) 
\quad {\rm when}\;  A_k \cap A_j = \emptyset \quad k\neq j
$;}
\endEnum

We now consider a random variable from which we will get a sub $\sigma$-algebra.
Let 
$$
g(D_i) = \cases{0 & if $i$ is even;\cr
1 & if $i$ is odd \cr 
}
$$
In a discrete space the $\sigma$-algebra generated from $g$ is the algebra of 
sets generated from the sets:
$g^{-1}(a)$, $a \in (-\infty, \infty)$. Clearly, the interesting sets come 
from the values $0$ and $1$, all other values lead to the empty set. Consequently,
$$
\eqalignno{
	{\cal F} & = \{\emptyset, \{D_1,D_3,D_5\}, \{D_2,D_4,D_6\}, \{D_1,D_2,D_3,D_4,D_5,D_6\}\} & \cr
}
$$
In a discrete space a function, $f$, is measurable with respect to a $\sigma$-algebra if 
$f^{-1}(a)$ is an element in the $\sigma$-algebra for all $a\in (-\infty, \infty)$.
This has implications for the $\sigma$-algebra ${\cal F}$. 

{\bf claim:\/} Any function, $f$,  
which is measurable over ${\cal F}$ has the property that $f$ is constant on the sets 
$\{D_1,D_3,D_5\}$ and $\{D_2,D_4,D_6\}$. More generally, we claim that any 
measurable function, $f$, in a given $\sigma$-algebra must be constant on 
the {\it minimal\/} elements of the algebra --  elements which have no non-trivial subsets.%
\footnote{\kern 0.5pt \raise 0.5ex \hbox{\dag}}{%
	Specifically, in a discrete setting, a set $Z$ in a $\sigma$-algebra, 
	${\cal H}$, is {\it minimal\/} in ${\cal H}$ if 
there is no non-empty, strict subset, $Y$, of $Z$ with $Y \in {\cal H}$.}

To see this suppose that $f(1)$ differs from $f(3)$.
Then the set, $A = \{D_1, D_3, D_5\} \cap f^{-1}(f(D_1))$, is a {\it strict\/}, non-trivial subset of 
$\{D_1, D_3, D_5\}$. This is true since $A$, by construction, is a subset of $\{D_1, D_3, D_5\}$;
$A$ contains $D_1$; and $A$ does not contain $D_3$.
Since ${\cal F}$ is a $\sigma$-algebra and $A$ is the intersection of the ${\cal F}$ measurable sets 
$\{D_1, D_3, D_5\}$ and $f^{-1}(f(D_1))$, $A$ must be in ${\cal F}$.
However, we know that $\{D_1, D_2, D_3\}$ has no strict non-trivial subset in ${\cal F}$  -- contradiction. 
Therefore, our premise that $f(D_1)$ and $f(D_3)$ could 
take differing values is incorrect.  The same argument shows that $f(D_1)$ and 
$f(D_5)$ do not differ.
One can repeat the above argument to show that
$f$ is constant on the other minimal set $\{D_2,D_4,D_6\}$.

Notice that while any function over the measure space $(P,X,{\cal E})$ is measurable, we 
can write down a specific function that is non-measurable with respect to ${\cal F}$.
We know that all we have to do is come up with a function that differs on either of the 
sets $\{D_1, D_3, D_5\}$ or $\{D_2, D_4, D_6\}$. For instance, the function:  
$f(D_i) = i$, for $i\in\{1,2,3,4,5,6\}$, 
is a non-measurable function in ${\cal F}$.

\section{Conditional Expectation}
Given a probability space $(P,X,{\cal E})$, the conditional expectation of a measurable 
function $f$ with respect to a sub $\sigma$-algebra ${\cal F}$ is the {\it unique\/} ${\cal F}$ 
{\it measurable\/} function labeled, $\E{f/{\cal F}}$, such that%
\footnote{\kern 0.5pt \raise 0.5ex \hbox{\ddag}}{%
That such a unique function exists is a consequence of the Radon-Nikodym theorem.}
$$
\eqalignno{
\int_{\Lambda} \E{f/{\cal F}} \, dP & 
= \int_{\Lambda} f \, dP \quad \forall \Lambda \in {\cal F} & (1a) \cr
}
$$
Let us write this again in, perhaps, an unusual way.
$$
\eqalignno{
	\int_{\Lambda} \E{f/{\cal F}} \, dP_{\cal F} & 
= \int_{\Lambda} f \, dP \quad \forall \Lambda \in {\cal F} & (1b) \cr
}
$$
In equation (1b) we use the fact that the conditional expectation is 
a {\it measurable\/} function with respect to ${\cal F}$.
We do this by replacing the measure $P$ on the left hand side with $P_{\cal F}$ to indicate
that we are using the same measure, but one that is restricted to the sub $\sigma$-algebra ${\cal F}$.

Although it seems that $f$ -- itself -- satisfies (1a), we have 
to be careful. Equation (1b)'s notation emphasizes that the conditional 
expectation function must be {\it measurable\/} with respect to the sigma 
algebra we are using for integration. On the right of equation (1b)
we are dealing with a ${\cal E}$ measurable 
function on ${\cal E}$, while on the left we are dealing with a 
${\cal F}$ measurable function. Consequently, while $f$ seems 
like a nature candidate for the conditional expectation it is not necessarily
${\cal F}$ measurable. 
However, if $f$ is measurable with respect to ${\cal F}$ then, by the definition above,  
it is its own conditional expectation. 

The modern theory of probability -- including conditional expectation -- 
relies on measure theory which has its roots in Lebesgue measure theory -- 
used to provide an alternative to the theory of Riemann Integration.
From Lebesgue Measure Theory one is introduced to measurable and non-measurable sets/functions. 
The problem, in the context of Lebesgue, is that non-measurable sets/functions exist but 
specific examples are hard to come by. However, non-measurable functions appear 
{\it implicitly\/} in the definition of conditional expectation 
in that if they didn't the definition wouldn't be of any interest.

If one started out learning measure theory from the Lebesgue theory, the 
definition of conditional expectation might make readers somewhat uneasy as 
we are confronted with non-measurable sets from the very start.
From this context, it is harder to get an intuitive idea of conditional expectation. 

In the next section we examine this measure theoretic version of conditional expectation 
in a discrete probabilistic setting where such non-measurable functions are 
simple and explicit. In the process, we will provide an intuitive idea of the 
measure-theoretic definition of conditional expectation which coincides with 
the traditional approach -- except in the ``singular'' case
which we discuss in the last section.

\section{Example Calculation of Conditional Expectation}
Consider the function from the second on an elementary dice example, $f(D_i) = i$, 
which is measurable in the space $(P,X,{\cal E})$. Let ${\cal F}$ be the 
sub $\sigma$-algebra of that section.
We now compute the conditional expectation of $f$ with respect to ${\cal F}$.
Using (1b) we choose the {\it minimal\/} sets: $\Lambda_1 = \{D_1,D_3,D_5\}$ 
and $\Lambda_2 = \{D_2,D_4,D_6\}$. Since the conditional expectation function is constant
on each of these sets, equation (1b) will provide a way to find each value on each the two sets.
Since the union of $\Lambda_1$ and $\Lambda_2$ constitute the entire set, $X$, we will know
the value of the conditional expectation function on all of $X$; hence we will know the
conditional expectation function.

Proceeding, we have
$$
\eqalignno{
	\int_{\Lambda_1} \E{f/{\cal F}} \, dP_{\cal F} & 
	= \int_{\Lambda_1} f \, dP & (2) \cr
}
$$
and
$$
\eqalignno{
	\int_{\Lambda_2} \E{f/{\cal F}} \, dP_{\cal F} & 
	= \int_{\Lambda_2} f \, dP & (3) \cr
}
$$
We know $\E{f/{\cal F}}$ is {\it constant\/} on $\Lambda_1$. We label this value as
$\E{f/{\cal F}}\!(\Lambda_1)$. From (2) we have 

$$
\eqalignno{
\int_{\Lambda_1} \E{f/{\cal F}} \, dP_{\cal F}  & =  \int_{\Lambda_1} f \, dP & \cr
\E{f/{\cal F}}\!(\Lambda_1) \int_{\Lambda_1} \, dP_{\cal F} & = \int_{\Lambda_1} f \, dP & \cr 
\E{f/{\cal_F}}\!(\Lambda_1) * P_{\cal F}(\Lambda_1) & =  \int_{\Lambda_1} f \, dP = f(D_1) * P(D_1) + f(D_3) * P(D_3) + f(D_5) * P(D_5) & (**) \cr 
\E{f/{\cal F}}\!(\Lambda_1)  & =  \int_{\Lambda_1} f \, dP = f(D_1) * \frac{P(D_1)}{P(\Lambda_1)} + f(D_3) * \frac{P(D_3)}{P(\Lambda_1)} + f(D_5) * \frac{P(D_5)}{P(\Lambda_1)} & \cr 
\E{f/{\cal F}}\!(\Lambda_1)  & =  \int_{\Lambda_1} f \, dP = 1 * \frac{\frac{1}{6}}{\frac{1}{2}} + 3 * \frac{\frac{1}{6}}{\frac{1}{2}} + 5 * \frac{\frac{1}{6}}{\frac{1}{2}} & \cr 
\E{f/{\cal F}}\!(\Lambda_1)  & =  \int_{\Lambda_1} f \, dP = 1 * \frac{1}{3} + 3 * \frac{1}{3} + 5 * \frac{1}{3} & \cr 
\E{f/{\cal F}}\!(\Lambda_1)  & = 3 & \cr
}
$$

Likewise, $\E{f/{\cal F}}$ is constant on the set $\Lambda_2$. 
As we did above, we find the value of $\E{f/{\cal F}}$ on the set $\Lambda_2$.
As with $\Lambda_1$, label $\E{f/{\cal F}}\!(\Lambda_2)$ as the constant value of $\E{f/{\cal F}}$ 
on $\Lambda_2$.
We have

$$
\eqalignno{
\int_{\Lambda_2} \E{f/{\cal F}} \, dP_{\cal F}  & =  \int_{\Lambda_2} f \, dP & \cr
\E{f/{\cal F}}\!(\Lambda_2) \int_{\Lambda_2} \, dP_{\cal F} & = \int_{\Lambda_2} f \, dP & \cr 
\E{f/{\cal_F}}\!(\Lambda_2) * P_{\cal F}(\Lambda_2) & =  \int_{\Lambda_2} f \, dP = f(D_2) * P(D_2) + f(D_4) * P(D_4) + f(D_6) * P(D_6) & \cr 
\E{f/{\cal F}}\!(\Lambda_2)  & =  \int_{\Lambda_2} f \, dP = f(D_2) * \frac{P(D_2)}{P(\Lambda_2)} + f(D_4) * \frac{P(D_4)}{P(\Lambda_2)} + f(D_6) * \frac{P(D_6)}{P(\Lambda_2)} & \cr 
\E{f/{\cal F}}\!(\Lambda_2)  & =  \int_{\Lambda_2} f \, dP = 2 * \frac{\frac{1}{6}}{\frac{1}{2}} + 4 * \frac{\frac{1}{6}}{\frac{1}{2}} + 6 * \frac{\frac{1}{6}}{\frac{1}{2}}  & \cr 
\E{f/{\cal F}}\!(\Lambda_2)  & =  \int_{\Lambda_2} f \, dP = 2 * \frac{1}{3} + 4 * \frac{1}{3} + 6 * \frac{1}{3} & \cr 
\E{f/{\cal F}}\!(\Lambda_2)  & = 4 & \cr
}
$$
Since a function is determined once we know what its values are on every $x \in X$, 
we have found the conditional expectation function, $\E{f/{\cal F}}$, as we know 
its values on every $x \in X$.\footnote{\kern 0.5pt \raise 0.5ex \hbox{$\dag$}}{%
In the ``Redux'' section we examine more closely what ``knowing the value on every $x$'' means.}

From equation $(**)$ we see, that the value of the function $\E{f/{\cal F}}$ 
evaluated on any `x' value in a minimal set, $\Lambda$, is% 
\footnote{\kern 0.5pt \raise 0.5ex \hbox{\ddag}}{%
The notation, $P_{\Lambda}$ means that we have normalized the measure, $P$, 
so that $P_{\Lambda}(\Lambda) = 1$. To do this we are {\it assuming\/} 
that $P(\Lambda) \ne 0$.}
$$
\eqalignno{
	\E{f/{\cal F}}\!(x) & = \frac{\int_\Lambda f \, dP}{P(\Lambda)} = \int_\Lambda f \, dP_{\Lambda} & (4) \cr
}
$$
That is, the value of the conditional expectation on any minimal set is the 
{\it weighted average\/} of $f$ over the minimal set. The weights are 
determined by normalizing the probability measure $P$ over the minimal set.

More generally, discrete probability or otherwise, we may think of the 
$\sigma$-algebra, ${\cal F}$, as a coarser ``mesh'' than the finer ``mesh'', 
$\sigma$-algebra, ${\cal E}$.
And we can think of the value of $\E{f/{\cal F}}$ on any ``minimal'' element 
of the mesh as the average of the function, $f$, over this minimal 
element with respect to the finer ``mesh''.

From this perspective, you can think of the conditional expectation as 
giving the ``best'' representation of a function given a cruder mesh, ${\cal F}$, 
than the refined mesh, ${\cal E}$. Just as the ``best'' representation of an 
image at a larger pixel scale (crude mesh) would be an average over smaller 
scale pixels (refined mesh) of the larger pixel.
 
\section{Example Redux}
Let's adjust the dice example probabilities and redo the calculation of the 
conditional expectation. Set the probability measure, $P$, as:
$$
\eqalignno{
	P(A) & = \frac{|A\cap \{D_1,D_3,D_5\}^c|}{3} \quad A \in {\cal E} & \cr
}
$$
That is, the probability of a set, $A$, is the number of die in $A$ that 
are not in the set $\{D_1, D_3, D_5\}$ divided by $3$.
With this definition, $P(\Lambda_1) = 0$ and $P(\Lambda_2) = 1$.

Given $P$, we can find the value of $\E{f/{\cal F}}$ on the set $\Lambda_2$ 
as before using equation (4).
However, we can't use it to find the value $\E{f/{\cal F}}$ on the 
set $\Lambda_1$ as $P(\Lambda_1) = 0$. 

It turns out, we don't have to determine the values with any specificity on $\Lambda_1$.
We can {\it set\/} the values of $\E{f/{\cal F}}$ on $\Lambda_1$ to $0$; or, 
to any other {\it single\/} value for that matter%
\footnote{\kern 0.5pt \raise 0.5ex \hbox{\dag}}{%
We know that $\Lambda_1$ is minimal; so, for the conditional expectation 
function to be measurable it must have the same value on all elements of $\Lambda_1$.}.
The reason for this is 
that the definition of conditional expectation determines a unique element in 
the function space on ${\cal F}$.
However, each element in such a space is actually an equivalence class of 
measurable functions over ${\cal F}$ who differ by a set of measure $0$. 

We can't directly compute what the value of a representative of $\E{f/{\cal F}}$ is on 
the set $\Lambda_1$, but we don't have to, since it's a set of measure $0$, any 
value on this set will give us a function that is in the equivalence class of 
the conditional expectation element.
Therefore, we may take $\E{f/{\cal F}}$ to be $0$ on $\Lambda_1$. This gives us 
a representative for the conditional expectation as we have values for all $x \in X$.
Through this representative we can produce the associated equivalence class of functions.
Consequently, we know $\E{f/{\cal F}}$ in the function space $L_2(P, X, {\cal F})$.

In the case of singular sets (set of probability $0$) we may revise equation (4) and write
that on minimal sets, $\E{f/{\cal F}}$ is constant and satisfies:

$$
\eqalignno{
	\E{f/{\cal F}}\!(x) * P(\Lambda) & = \int_\Lambda f \, dP & (5) \cr
}
$$

Here, with a measure theoretic methodology, we have an elegant way to talk about 
conditional expectation in a singular context that doesn't exist in the 
traditional approach.

\section{A Discrete Conditional Expectation Result}
Let $X$ be a set with a finite number of elements.
For any given $\sigma$-algebra, ${\cal F}$, (in this case algebra) of sets of $X$, let $\mathop{\cup}_{i=1}^N\limits M_i$
be the set of all distinct minimal sets in ${\cal E}$. This set exists as we are dealing with a finite set $X$
with a finite power set $2^X$. Each set is either a minimal set or not. In 
writing $\mathop{\cup}_{i=1}^N\limits M_i$ we are simply collecting all of the sets which are minimal in ${\cal F}$.

{\bf claim:\/} 
The set $\{M_i\}_{i=1}^N$ is a {\it partition\/} of the set $X$.
Meaning:

\beginEnum
	\item{$\forall i,j \in 1:N \quad M_i \cap M_j = \emptyset \quad (i \ne j)$;}
	\item{$X = \mathop{\cup}_{i=1}^N\limits M_i$.}
	\item{The ($\sigma$-)algebra, ${\cal G}$, generated by the sets $\mathop{\{M_i\}}_{i=1}^N\limits$, is the 
	power set of the sets $\mathop{\{M_i\}}_{i=1}^N\limits$.}
\endEnum
We already know that minimal sets must have the first property otherwise if there were
two minimal sets whose intersection was not $\emptyset$ then the sets would either be the same
or they would each have a strict non-trivial subset which can't be as they are minimal.

We prove the second property by contradiction. If the union of minimal sets did not span $X$,
then the set $Z_0 = \bigl\{\mathop{\cup}_{i=1}^N\limits M_i\bigr\}^c$ is non-empty. The set $Z_0$ cannot be
minimal as we have already accounted for all minimal sets in our collect. The set ${\cal H} = 2^{Z_0} \backslash Z_0$, the
power set of $Z_0$ less $Z_0$. Note that for $Z_0$ to be non-minimal, it cannot consist of $1$ element.  
Therefore, ${\cal H}$ is a non-empty collection of sets. If none of these sets are in ${\cal E}$, this
implies that $Z_0$ is minimal  -- a contradiction. Therefore, there must be a non-trivial strict subset of 
$Z_0$, $Z_1$, that is in ${\cal E}$. We can repeat this argument with $Z_1$ to 
produce, $Z_2$, $\ldots Z_i$ producing $Z_{i+1}$, etc; noting, that each time this
is done the number of elements in the current ``$Z$ set'' decreases by at least $1$. 
Consequently, the process cannot proceed indefinitely. Let $m$ be the step 
where this process fails; that is, there is no strict subset, $Z_m$, of set $Z_{m-1}$
which is a subset of ${\cal E}$. But this means that means that 
$Z_m$ is minimal by definition -- contradiction.
Consequently, the second property holds.

The third property follows as none of the $\mathop{\{M_i\}}_{i=1}^N$ can produce sets of 
finer granularity than themselves, they behave as if they were single elements. Therefore,
the only way to produce new sets is by union, and consequently, the collection of 
all elements generated is the power set of $\mathop{\{M_i\}}_{i=1}^N$.

We now examine the expectation of the conditional expectation, $\E{f / {\cal G}}$.

$$
\eqalignno{
	\int_{X} \E{f / {\cal G}} \, dP_{\cal G} & = \int_{X} f \, dP & (6) \cr
									         & = \int_{\mathop{\cup}_{i=1}^N\limits M_i} f \, dP & \cr
											 & = \sum_{i=1}^N \int_{M_i} f \, dP & \cr
											 & = \sum_{i=1}^N \int_{M_i} \E{f / {\cal G}} \, dP_{\cal G} &\cr
											 & = \sum_{i=1}^N \E{f / {\cal G}}\!(M_i)\, P(M_i) & (7) \cr
}
$$
In equation (6) we have the following identity: $E[\E{f /{\cal G}}]= E[f]$.
From equation (7) we have that the expectation of the conditional expectation of a $\sigma$-algebra
generated by minimal sets is just the weighted sum of the values of the conditional expectation on these sets.

Finally, if $g$ is a discrete function, the collection of all non-trivial sets of the form $g^{-1}(a) \quad a \in (-\infty, \infty)$
is a finite collection of set $\mathop{\{M_i\}}_{i=1}^N$ for some positive integer $N$. The power set of these 
sets generates an algebra, ${\cal G}$, with each $M_i$ minimal in this algebra. We write $\E{f / g}$ to mean $\E{f / {\cal G}}$.
Consequently, we may write the above as:

$$
\eqalignno{
	\int_{X} \E{f / g} \, dP & = \int_{X} f \, dP & (6') \cr
									         & = \int_{\mathop{\cup}_{i=1}^N\limits M_i} f \, dP & \cr
											 & = \sum_{i=1}^N \int_{M_i} f \, dP & \cr
											 & = \sum_{i=1}^N \int_{M_i} \E{f / g} \, dP &\cr
											 & = \sum_{i=1}^N \E{f / g}\, P(M_i) & (7') \cr
}
$$
Here, in the term, $\E{f / g} P(M_i)$, $\E{f / g}$ is interpreted as the value of $\E{f / {\cal G}}$ on the set $M_i$.
We also drop the $dP_{\cal G}$ notation, which was only used as a crutch in the previous part of the paper.
Lastly, we know from equation (5) how to compute the values of $\E{f / g}$ for all $M_i$ -- even when the probability of
a ``g'' event is $0$.


\bye


