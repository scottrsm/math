\documentclass[12pt]{article}

\usepackage{amsmath}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{7.5in}
\setlength{\hoffset}{-0.75in}
\setlength{\voffset}{-0.75in}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.5\baselineskip}

\input{latex_macros.tex}

\title{Constructing Diversification Constraints}
\author{R. Scott McIntire}
\date{Oct 27, 2024}

\newtheorem{theorem}{Theorem}
\newtheorem{DD}{Def}

\begin{document}

\maketitle

\section{Overview}
Consider the function, $f: {\bf R}^n \mapsto {\bf R}$, defined by%
\footnote{
For a given vector, ${\bf x} \in {\bf R}^n$, create a vector,  
${\bf x}^\prime$,
by {\it stably\/} sorting ${\bf x}$ from highest to lowest.
Define the notation, $x_{[i]}$ by: $x_{[i]} \equiv x_{i}^\prime$.
Note: For the rest of this paper we assume that $k \in {\bf Z}^+$ with $k \le n$.}
\begin{eqnarray}
	f({\bf x}) & = & \sum_{i=1}^k x_{[i]} 
\end{eqnarray}
From this we see that $f({\bf x})$ is the value of the sum of the $k^{\rm th}$ 
largest values of its input ${\bf x}$.
We are interested in optimization problems involving a vector ${\bf x}$ 
with the sum of the top values constrained by a given value; that is, 
such that $f({\bf x}) \le M$ for some value $M$.
How could we do this? One way is to write down all possible combinations of the 
$k$ elements of ${\bf x}$ and write a constraint that bounds their sum to be 
less than or equal to $M$.  But the number of constraints that one has to 
write is $n \choose k$. This becomes large very quickly. 
In the next section we seek a way to represent $f$ to 
reduce the number of constraints.%
\footnote{A bold font is used to denote vectors. We refer to a  
vector of $0$s as ${\bf 0}$, and likewise we refer to a vector of $1$s
as ${\bf 1}$. The mathematical expression, ${\bf a} \preceq {\bf b}$, is to be 
interpreted as the statement that every element of the vector ${\bf a}$ is 
less than or equal to the corresponding element in the vector ${\bf b}$. 
Similarly, the expression, ${\bf a} \succeq {\bf b}$, is the statement that 
each element of ${\bf a}$ is greater than or equal to each 
corresponding element of ${\bf b}$.
}

This constraint often arises in the world of finance where one wants to 
create (or modify) a portfolio so that the new portfolio has the property
that its top $k$ securities (notionally) do not exceed some fixed percentage 
of its total notional.

\section{The Function $f$ as an Optimization Problem}
We wish to characterize the value of $f$ on a given vector, ${\bf x}$, as 
the result of an optimization.
We claim that for a given ${\bf x}$, $f({\bf x})$ is the value of 
a solution to the following constrained {\em discrete\/} optimization problem:%
\begin{eqnarray}
	\mathop{\rm max}_{{\bf y} \in {\bf Z}_2^n}\limits \quad {\bf y}^T {\bf x} && \label{discrete_objective} \\
{\bf y}^T {\bf 1} & = & k \label{discrete_integral} 
\end{eqnarray}
In English this says: ``Take the maximum value of all possible sums of $k$ 
values from ${\bf x}$.'' This is clearly just another way of restating $f({\bf x})$.
Although this optimization is succinct, there are still an exponential number 
of combinations to examine to find the optimal solution in this discrete setting.

{\bf claim:} The discrete optimization problem is equivalent to the following continuous problem:%
\footnote{%
A solution to the continuous problem exists as the supremum of a {\it continuous\/}
objective function over a closed, bounded set in $R^n$ -- 
as determined by these particular constraints -- is attained. Hence,
we may use the term ``max'' rather than ``supremum'' for the optimal
objective value.
}
\begin{eqnarray}
\mathop{\rm max}_{{\bf y} \in {\bf R}^n}\limits \quad {\bf y}^T {\bf x} &&  \\
{\bf 0} \preceq {\bf y}   \preceq  {\bf 1}&& \label{bound} \\ 
{\bf y}^T {\bf 1}  =  k && \label{integral} 
\end{eqnarray}
{\bf proof:}
Since its domain, ${\bf R}^n$, 
includes ${\bf Z}_2^n$, a solution to the continuous problem is at least as 
large as any solution of the original discrete problem.
We now show the reverse, by showing that for a given optimal solution to the 
continuous problem, ${\bf y}^*$, there is a corresponding ${\bf y}^\prime$ that 
lives in ${\bf Z}_2^n$, satisfying the constraint, (\ref{discrete_integral}), 
with (\ref{discrete_objective}) yielding the same value for its objective 
as the optimal value of the continuous problem.

To this end, let ${\bf y}^* \in {\bf R}^n$ be a solution to the continuous 
problem. If all of the values are integral, by (\ref{bound}), 
the only integral values are $0$ or $1$. In this case, we are done -- take 
${\bf y}^\prime$ to be ${\bf y}^*$.

Otherwise, collect the components of ${\bf y}^*$ 
that are non-integral; that is, have values strictly between $0$ and $1$.
By the constraint, (\ref{integral}), the sum of these non-integral components
must sum to an integral value. Consequently, there must be more than one such
component. It must also be the case that amongst these non-integral components 
the corresponding ``x'' values are the same. Otherwise, if two of these components 
had differing ``x'' values, then the ``y'' component with the 
smaller ``x'' value could shift some of its value to the ``y'' component with 
the larger ``x'' value in such a way as to preserve the constraints, 
(\ref{bound}) and (\ref{integral}). 
But then we would have a larger objective value than the supposed maximum 
-- contradiction. Therefore, all of the 
``x'' components associated with non-integral ``y'' values must have the same 
value. As previously stated, the sum of these non-integral values must sum 
to an integral value, which by necessity, is less than the number of 
non-integral components in ${\bf y}^*$. Let us call this number, $j$. 
Pick any $j$ of these non-integral values, and let $J$ be the set of their index
values in ${\bf y}^*$.
Let ${\tilde J}$ be the set of indices corresponding to the remaining non-integral values
of ${\bf y}^*$.

Now, create a new 
vector ${\bf y}^\prime \in {\bf Z}_2^n$ and set its values in the following way: 
Set the values of ${\bf y}^\prime$ corresponding to the indices in $J$
to be $1$. Set the values of ${\bf y}^\prime$ corresponding to the indices in ${\tilde J}$
to $0$. Note that with this assignment, the sum of the elements of 
${\bf y}^*$ with indices in $J \cup {\tilde J}$ is the same as the sum over ${\bf y}^\prime$ 
with indices in $J \cup {\tilde J}$.
Set the rest of the components of ${\bf y}^\prime$ to the 
corresponding values from ${\bf y}^*$. By our construction, 
${{\bf y}^\prime}^T {\bf x} = k$. By constraint, (\ref{bound}), the integral 
values of ${\bf y}^\prime$ which came from ${\bf y}^*$, must
be either $0$ or $1$. It follows that ${\bf y}^\prime \in {\bf Z}_2^n$ and 
satisfies the constraint of the discrete problem, (\ref{discrete_integral}). 
Therefore, ${\bf y}^\prime$ is in the feasible set of the discrete problem and 
attains the optimal value of the continuous problem; meaning, that the 
solution to the discrete problem is at least as large as any solution to the 
continuous problem. Consequently, the two optimization problems are equivalent.

Note that the solution to the continuous problem is the same as the associated problem:
\begin{eqnarray}
	\mathop{\rm min}_{{\bf y} \in {\bf R}^n}\limits \quad -{\bf y}^T {\bf x} && \label{op1} \\ 
	{\bf 0} \preceq {\bf y} \preceq {\bf 1} &&  \label{op2}\\
	{\bf y}^T {\bf 1} =  k \label{op3} &&
\end{eqnarray}
Treating ${\bf x}$ as a constant, this is a {\it convex\/} optimization problem.

\section{A Dual Description of the Optimization}
Since the problem described by equations ($\ref{op1}, \ref{op2}, \ref{op3}$), is
{\it convex\/}, the value of its solution is the same as the value of 
its associated {\it dual\/} problem.%
\footnote{Normally one needs to show that a convex problem satisfies Slater's condition
	in order to claim that it provides the same value as its associated dual.
But this is not necessary when dealing with {\it linear\/} convex problems. 
Why, you may ask is it {\it linear\/}? The term $-{\bf y}^T {\bf x}$ is
decidedly non-linear. It is linear if we treat ${\bf x}$ as a constant (we also
use the term parameter).}

To form the dual problem we need the Lagrangian, which is:%
\footnote{For the purposes of this optimization, ${\bf x}$ is seen as a parameter
to the optimization -- essentially a constant with respect to the optimization.
As such, it is customary to treat such parameters as part of a function but separate
them from the ``true'' list of variables of the problem with a semi-colon.}
\begin{eqnarray}
	L({\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) &=& 
	-{\bf y}^T {\bf x} - {\boldsymbol \lambda}_1^T {\bf y} 
	+ {\boldsymbol \lambda}_2^T ({\bf y} - {\bf 1}) + \nu (k - {\bf y}^T {\bf 1}) 
\end{eqnarray}
Here ${\boldsymbol \lambda}_1$, ${\boldsymbol \lambda}_2 \in {\bf R}^n$ and $\nu \in R$
are the {\it dual\/} variables.

Set the function $g$:
\begin{eqnarray}
	g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_1, \nu; {\bf x}) &=& 
		\mathop{\rm inf}_{\bf y} 
		\; L({\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) 
\end{eqnarray}

Substituting for $L$ this becomes
\begin{eqnarray}
	g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_1, \nu; {\bf x}) &=& 
		\mathop{\rm inf}_{\bf y}
		\; \left({\bf y}^T \left( -{\bf x} - {\boldsymbol \lambda}_1 + {\boldsymbol \lambda}_2 - \nu {\bf 1} \right) \right.
		- \left. {\bf 1}^T {\boldsymbol \lambda}_2 + \nu \, k  \right)
\end{eqnarray}

The dual problem is then
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda}_2 \succeq {\bf 0}} \atop {{{\boldsymbol \lambda}_1 \succeq {\bf 0}} \atop \nu}} 
		\; g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) & & 
\end{eqnarray}

Which is%
\footnote{Note that $g$ is $-\infty$, unless the term that ${\bf y}$ is ``dotting'' is the zero vector. Consequently, the maximum
must necessarily occur where the dotting vector is zero.}
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda}_2 \succeq {\bf 0}} \atop {{{\boldsymbol \lambda}_1 \succeq {\bf 0}} \atop \nu}} 
		 & - {\bf 1}^T {\boldsymbol \lambda}_2 + \nu \, k   & \\ 
		 & - {\boldsymbol \lambda}_1 + {\boldsymbol \lambda}_2 - \nu {\bf 1} = {\bf x} & 
\end{eqnarray}

This is equivalent to%
\footnote{We can remove $n$ variables by eliminating ${\boldsymbol \lambda}_1$ from the equations while keeping
	the same number of inequalities. We can do this by realizing that ${\boldsymbol \lambda}_2 - \nu {\bf 1} = {\bf x} + {\boldsymbol \lambda}_1$ 
	expresses the same information as ${\boldsymbol \lambda}_2 - \nu {\bf 1} \succeq {\bf x}$. Since there is now only one ${\boldsymbol \lambda}$,
we relabel ${\boldsymbol \lambda}_2$ as ${\boldsymbol \lambda}$.}
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda} \succeq {\bf 0}} \atop \nu} 
		& \quad \nu \, k - {\bf 1}^T {\boldsymbol \lambda} & \\   
		& {\bf x} \preceq {\boldsymbol \lambda} - \nu {\bf 1} &
 \end{eqnarray}
Since maximizing over $\nu$ or $-\nu$ is the same -- as there are no restrictions 
on $\nu$  -- we may replace $\nu$ with $-\nu$ in the last equations giving:
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda} \succeq {\bf 0}} \atop \nu} 
		& \quad -\nu \, k - {{\bf 1}^T \boldsymbol \lambda} & \\ 
	    &  {\bf x} \preceq {\boldsymbol \lambda} + \nu {\bf 1} &
 \end{eqnarray}
But this is the same as:

\begin{eqnarray}
	\mathop{\rm min}_{{\boldsymbol \lambda}, \nu} & \quad \nu \, k + {\bf 1}^T {\boldsymbol \lambda} & \\ 
												  &  {\bf x} \preceq {\boldsymbol \lambda} + \nu {\bf 1} & \\
												  & {\boldsymbol \lambda} \succeq {\bf 0} & 
 \end{eqnarray}

\section{Characterization of $f$ as O(n) Linear Constraints}
We now apply the results of the previous sections to the following problem:
Add constraints to an optimization problem that includes a {\it variable} ${\bf x} \in {\bf R}^n$
so that $f({\bf x}) \le M$ for some value $M$.

We claim that one can bound $f({\bf x})$ by adding two new variables,
${\boldsymbol \lambda} \in {\bf R}^n$ 
and $\nu \in R$, along with the following three constraints:
\begin{eqnarray}
	\nu \, k + {\bf 1}^T {\boldsymbol \lambda}  & \le & M \label{opp1} \\ 
	{\bf x} & \preceq & {\boldsymbol \lambda} + \nu {\bf 1} \label{opp2} \\
	{\boldsymbol \lambda} & \succeq & {\bf 0}  \label{opp3}
\end{eqnarray}

Why? Because the expression $\nu \, k + {\bf 1}^T {\boldsymbol \lambda}$ with
the constraints (\ref{opp2}) and (\ref{opp3}) applied is {\it always\/} 
an upper bound to $f({\bf x})$. 
Consequently, we have the inequality: 
$f({\bf x}) \le \nu \, k + {\bf 1}^T {\boldsymbol \lambda} \le M$.
The only concern remaining is that there may be a gap between the values of 
$\nu \, k + {\bf 1}^T {\boldsymbol \lambda}$ 
and $f({\bf x})$ -- making (\ref{opp1}) too restrictive. 
But this is not the case as the minimum over all ${\boldsymbol \lambda}$ 
and $\nu$ (subject to (\ref{opp2}) and (\ref{opp3})) is $f({\bf x})$.
Another way of saying this is that the parameters, ${\boldsymbol \lambda}$ 
and $\nu$ provide enough freedom to ${\bf x}$ so that $f({\bf x})$ can be 
as close to $M$ as one would like.


One might ask why we couldn't do exactly the same procedure with the ``simpler''
characterization we had with equations
(\ref{op1}), (\ref{op2}), and (\ref{op3}), rather than going through so much 
effort with a dual problem. The same number of variables and the same number 
of constraints are required.

We could do that; however, note that once we take the characterization of a 
bound on a ``given'' ${\bf x}$ and place it into an optimization problem, that 
``given'' ${\bf x}$ is no longer a constant. It, itself, is part of the 
optimization. And now, one of the inequalities that we would add
would be related to (\ref{op1}); that is, the term: $-{\bf y}^T {\bf x}$. But 
this term involves the (now) {\it variable\/}, ${\bf x}$, and the new 
{\it variable\/}, ${\bf y}$, in a decidedly {\it non-linear\/} way.
In fact, the term is not even {\it convex\/}.

In contrast to this ``simpler'' characterization and the original n{\"a}ive 
combinatorial approach, we have shown that 
by examining an associated dual problem, $f({\bf x})$ can be bounded by
adding $(n+1)$ new variables and $(2n + 1)$ {\it linear\/} constraints.

\end{document}

