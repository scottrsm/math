\documentclass[12pt]{article}

\usepackage{amsmath}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{7.5in}
\setlength{\hoffset}{-0.75in}
\setlength{\voffset}{-0.75in}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.5\baselineskip}

\input{latex_macros.tex}

\title{Constructing Diversification Constraints}
\author{R. Scott McIntire}
\date{Oct 8, 2024}

\newtheorem{theorem}{Theorem}
\newtheorem{DD}{Def}

\begin{document}

\maketitle

\section{Overview}
Consider the function function, $f: {\bf R}^n \mapsto {\bf R}$, defined by
\begin{eqnarray}
	f({\bf x}) & = & \sum_{i=1}^k x_{[i]} 
\end{eqnarray}
From this we see that $f({\bf x})$ is the value of the sum of the $k^{\rm th}$ 
largest values of its input ${\bf x}$.
We are interested in optimization problems involving a vector ${\bf x}$ 
with the sum of the top values constrained by a given value; that is, 
such that $f({\bf x}) \le M$  for some value $M$.
How could we do this? One way is to write down all possible combinations of the 
$k$ elements of ${\bf x}$ and write a constraint that bounds their sum to be 
less than or equal to $M$.  But the number of constraints that one has to 
write is $n \choose k$. This becomes large very quickly. 
In the next section we seek a way to represent $f$ to 
reduce the number of constraints.

This constraint often arises in the world of finance where one wants to 
create (or modify) a portfolio so that the new portfolio has the property
that its top $k$ securities (notionally) do not exceed some fixed percentage 
of its total notional.

\section{The Function $f$ as an Optimization Problem}
We wish to characterize the value of $f$ on a given vector, ${\bf x}$ as 
the result of an optimization.
We claim that for for a given ${\bf x}$, $f({\bf x})$ is the value of 
the following constrained optimization problem:%
\footnote{A bold font is used to denote vectors. We refer to a  
vector of $0$s as ${\bf 0}$, and likewise we refer to a vector of $1$s
as ${\bf 1}$. Finally, the statement, ${\bf a} \preceq {\bf b}$, is the 
statement that every element of the vector ${\bf a}$ is less than or equal
to the corresponding element in the vector ${\bf b}$. The statement,
${\bf a} \succeq {\bf b}$, is similar but with each element of ${\bf a}$
greater than or equal each corresponding element of ${\bf b}$.
}
\begin{eqnarray}
\mathop{\rm max}_{{\bf y} \in {\bf Z}_2^n}\limits \quad {\bf y}^T {\bf x} && \\
{\bf y}^T {\bf 1} & = & k 
\end{eqnarray}
In English this says: ``Take the maximum value of all possible sums of $k$ 
values from ${\bf x}$.'' This is clearly just another way of restating $f({\bf x})$.
Although this optimization is succinct, there are still an exponential number 
of combinations to examine to find the optimal solution in this discrete setting.

{\bf claim:} The solution to the above is the same as the solution to the 
{\it continuous\/} optimization problem: 
\begin{eqnarray}
\mathop{\rm max}_{{\bf y} \in {\bf R}^n}\limits \quad {\bf y}^T {\bf x} &&  \\
{\bf 0} \preceq {\bf y}   \preceq  {\bf 1}&& \\ 
{\bf y}^T {\bf 1}  =  k && \label{integral} 
\end{eqnarray}
{\bf proof:}
Since its domain, ${\bf R}^n$, 
includes ${\bf Z}_2^n$, the solution to the continuous problem is at least as 
large as the solution to the original discrete problem.
We now show the reverse, by showing that for every optimal solution to the 
continuous problem, ${\bf y}^*$, there is a corresponding ${\bf y}^\prime$ that 
lives in ${\bf Z}_2^n$ yielding the same value for the objective.

To this end, let ${\bf y}^*$ be a solution to the continuous problem. If all
of the values are integral; meaning, take on only the values of $0$ or $1$ we 
are done. Otherwise, collect the components of ${\bf y}^*$ that are non-integral.
By the constraint, (\ref{integral}), there must be more than one component. 
It must also be the case that amongst these ``fractional'' components that
the corresponding ``x'' values are the same. Otherwise, If two of the components 
of ${\bf y}$ had differing ``x'' values, then the ``y'' component with the 
smaller ``x'' value could shift some of its value to the ``y'' component with 
the larger ``x'' value in a way that keeps the constraint, (\ref{integral}). 
But then we would have a larger objective value that the supposed maximum 
-- contradiction. Therefore, all of the 
``x'' components associated with non-integral ``y'' values must have the same 
value. The sum of these non-integral values must sum to an integral value, which 
by necessity, is less than the number of components in ${\bf y}^*$. Suppose 
this number is $j$. Take any $j$ of these ``y'' components. Create a new 
vector ${\bf y}^\prime$ and set its values in the following way: Set the 
components of ${\bf y}^\prime$ corresponding to the previous $j$ components 
from ${\bf y}^*$ to be $1$. Set the components of ${\bf y}^\prime$ that 
correspond to the remaining ``fractional'' components of ${\bf y}^*$ to $0$. 
Set the rest of the components of ${\bf y}^\prime$ to the 
corresponding values from ${\bf y}^*$. We have now shown that a solution vector 
to the continuous problem is in the feasible set of the discrete problem. 
Therefore, the optimal solution to the discrete problem is at least as large as 
the solution to the continuous problem. Consequently, the two problems are 
equivalent.

Note that the solution to continuous problem is the same as the associated problem:
\begin{eqnarray}
	\mathop{\rm min}_{{\bf y} \in {\bf R}^n}\limits \quad -{\bf y}^T {\bf x} && \label{op1} \\ 
	{\bf 0} \preceq {\bf y} \preceq {\bf 1} &&  \label{op2}\\
	{\bf y}^T {\bf 1} =  k \label{op3} &&
\end{eqnarray}
But this problem is a {\it convex\/} problem.

\section{A Dual Description of the Optimization}
Since the problem described by equations ($\ref{op1}, \ref{op2}, \ref{op3}$), is
a {\it convex\/} problem, the value of its solution is the same as the value of 
its associated {\it dual\/} problem.%
\footnote{Normally one needs to show that a convex problem satisfies Slater's condition
	in order to claim that it provides the same value as its associated dual.
But this is not necessary when dealing with {\it linear\/} convex problems. 
Why, you may ask is it {\it linear\/}? The term $-{\bf y}^T {\bf x}$ is
decidedly non-linear. It is linear if we treat ${\bf x}$ as a constant (we also
use the term parameter).}

To form the dual problem we need the Lagrangian, which is:%
\footnote{For the purposes of this optimization, ${\bf x}$ is seen as a parameter
to the optimization -- essentially a constant with respect to the optimization.
As such, it is customary to treat such parameters as part of a function but separate
them from the ``true'' list of variables of the problem with a semi-colon.}
\begin{eqnarray}
	L({\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) &=& 
	-{\bf y}^T {\bf x} - {\boldsymbol \lambda}_1^T {\bf y} + {\boldsymbol \lambda}_2^T ({\bf y} - {\bf 1}) + \nu (k - {\bf y}^T {\bf 1}) 
\end{eqnarray}

Set the function $g$:
\begin{eqnarray}
	g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_1, \nu; {\bf x}) &=& 
		\mathop{\rm inf}_{{{\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2 \in {\bf R}^n} \atop \nu \in R} 
		\; L({\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) 
\end{eqnarray}

Substituting for $L$ this becomes
\begin{eqnarray}
	g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_1, \nu; {\bf x}) &=& 
		\mathop{\rm inf}_{{{\bf y}, {\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2 \in {\bf R}^n} \atop \nu \in R} 
		\; \left({\bf y}^T \left( -{\bf x} - {\boldsymbol \lambda}_1 + {\boldsymbol \lambda}_2 - \nu {\bf 1} \right) \right.
		- \left. {\bf 1}^T {\boldsymbol \lambda}_2 + \nu \, k  \right)
\end{eqnarray}

The dual problem is then
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda}_2 \succeq {\bf 0}} \atop {{{\boldsymbol \lambda}_1 \succeq {\bf 0}} \atop \nu}} 
		\; g({\boldsymbol \lambda}_1, {\boldsymbol \lambda}_2, \nu; {\bf x}) & & 
\end{eqnarray}

Which is%
\footnote{Note that $g$ is $-\infty$, unless the term that ${\bf y}$ is ``dotting'' is the zero vector. Consequently, the maximum
must necessarily occur where the dotting vector is zero.}
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda}_2 \succeq {\bf 0}} \atop {{{\boldsymbol \lambda}_1 \succeq {\bf 0}} \atop \nu}} 
		 & - {\bf 1}^T {\boldsymbol \lambda}_2 + \nu \, k   & \\ 
		 & - {\boldsymbol \lambda}_1 + {\boldsymbol \lambda}_2 - \nu {\bf 1} = {\bf x} & 
\end{eqnarray}

This is equivalent to%
\footnote{We can remove $n$ variables by eliminating ${\boldsymbol \lambda}_1$ from the equations while keeping
	the same number of inequalities. We can do this by realizing that ${\boldsymbol \lambda}_2 - \nu {\bf 1} = {\bf x} + {\boldsymbol \lambda}_1$ 
	expresses the same information as: ${\boldsymbol \lambda}_2 - \nu {\bf 1} \succeq {\bf x}$. Since there is now only one ${\boldsymbol \lambda}$,
we relabel ${\boldsymbol \lambda}_2$ as ${\boldsymbol \lambda}$.}
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda} \succeq {\bf 0}} \atop \nu} 
		& \quad \nu \, k - {\bf 1}^T {\boldsymbol \lambda} & \\   
		& {\bf x} \preceq {\boldsymbol \lambda} - \nu {\bf 1} &
 \end{eqnarray}
Since maximizing over $\nu$ or $-\nu$ is the same and there are no restrictions on the sign of $\nu$ we may replace $\nu$ with $-\nu$ 
in the last equations giving:
\begin{eqnarray}
	\mathop{\rm max}_{{{\boldsymbol \lambda} \succeq {\bf 0}} \atop \nu} 
		& \quad -\nu \, k - {{\bf 1}^T \boldsymbol \lambda} & \\ 
	    &  {\bf x} \preceq {\boldsymbol \lambda} + \nu {\bf 1} &
 \end{eqnarray}
But this is the same as:

\begin{eqnarray}
	\mathop{\rm min}_{{\boldsymbol \lambda}, \nu} & \quad \nu \, k + {\bf 1}^T {\boldsymbol \lambda} & \\ 
												  &  {\bf x} \preceq {\boldsymbol \lambda} + \nu {\bf 1} & \\
												  & {\boldsymbol \lambda} \succeq {\bf 0} & 
 \end{eqnarray}

\section{Characterization of $f$ as O(n) Linear Constraints}
If one wishes to bound the top $k$ elements of the {\it variable\/} 
${\bf x} \in {\bf R}^n$ in an optimization problem. That is, 
bound $f({\bf x})$ above by the value $M$, 
one needs to add two new variables, ${\boldsymbol \lambda} \in {\bf R}^n$ 
and $\nu \in R$ along with the following three constraints:
\begin{eqnarray}
	\nu \, k + {\bf 1}^T {\boldsymbol \lambda}  & \le & M \label{opp1} \\ 
	{\bf x} & \preceq & {\boldsymbol \lambda} + \nu {\bf 1} \label{opp2} \\
	{\boldsymbol \lambda} & \succeq & {\bf 0}  \label{opp3}
\end{eqnarray}

Why? Because the expression $\nu \, k + {\bf 1}^T {\boldsymbol \lambda}$ with
the constraints (\ref{opp2}) and (\ref{opp3}) applied is {\it always\/} 
an upper bound to $f({\bf x})$. 
Consequently, we have the inequality: 
$f({\bf x}) \le \nu \, k + {\bf 1}^T {\boldsymbol \lambda} \le M$.
The only concern remaining is that there may be a gap between the values of 
$\nu \, k + {\bf 1}^T {\boldsymbol \lambda}$ 
and $f({\bf x})$ -- making (\ref{opp1}) too restrictive. 
But this is not the case as the minimum over all ${\boldsymbol \lambda}$ 
and $\nu$ (subject to (\ref{opp2}) and (\ref{opp3})) is $f({\bf x})$.
Another way of saying this is that the parameters, ${\boldsymbol \lambda}$ 
and $\nu$ provide enough freedom to ${\bf x}$ so that $f({\bf x})$ can be 
as close to $M$ as one would like.


One might ask why we couldn't do exactly the same procedure with the ``simpler''
characterization we had with equations
(\ref{op1}), (\ref{op2}), and (\ref{op3}), rather than going through so much 
effort with a dual problem. The same number of variables and the same number 
of constraints are required.

We could do that; however, note that once we take the characterization of a 
bound on a ``given'' ${\bf x}$ and place it into an optimization problem, that 
``given'' ${\bf x}$ is no longer a constant. It, itself, is part of the 
optimization. And now, one of the inequalities that we would add
would be related to (\ref{op1}); that is, the term: $-{\bf y}^T {\bf x}$. But 
this term involves the (now) {\it variable\/}, ${\bf x}$, and the new 
{\it variable\/}, ${\bf y}$, in a decidedly {\it non-linear\/} way.
In fact, the term is not even {\it convex\/}.

In contrast to this ``simpler'' characterization and the original n{\"a}ive 
combinatorial approach, we have shown that 
by examining an associated dual problem, $f({\bf x})$ can be bounded by
adding $(n+1)$ new variables and $(2n + 1)$ {\it linear\/} constraints.

\end{document}

